{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "eltOBiEb4Vcb"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import smtplib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "URL = 'https://www.amazon.com/Funny-Data-Systems-Business-Analyst/dp/B07FNW9FGJ/ref=sr_1_3?dchild=1&keywords=data%2Banalyst%2Btshirt&qid=1626655184&sr=8-3&customId=B0752XJYNL&th=1'\n",
        "\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
        "page = requests.get(URL, headers=headers)\n",
        "response = requests.get(URL)\n"
      ],
      "metadata": {
        "id": "UL1-nVVCzIKW"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(response.text, 'lxml')\n",
        "\n",
        "#Utilising css selectors\n",
        "#here I utilized lxml to parse\n",
        "\n",
        "title_element = soup.select_one(\"#productTitle\")\n",
        "title = title_element.text.strip()\n",
        "\n",
        "rating_element = soup.select_one(\"#acrPopover\")\n",
        "rating = rating_element.get(\"title\")\n",
        "rating = rating.replace('out of 5 stars', '')\n",
        "\n",
        "price_element = soup.select_one('span.a-price').select_one('span.a-offscreen')\n",
        "price = price_element.text.strip()\n",
        "\n",
        "image_element = soup.select_one(\"#imgTagWrapperId img\")\n",
        "image_url = image_element.get(\"src\")\n",
        "\n",
        "print(title)\n",
        "print(rating)\n",
        "print(price)\n",
        "print(image_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ErTJvmqz7vp",
        "outputId": "258f8a04-d8ae-4569-8ed0-f03cc0f4cb7a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got Data Funny Business Data Analyst T-Shirt\n",
            "4.4 \n",
            "$19.99\n",
            "https://m.media-amazon.com/images/I/B1pppR4gVKL._CLa%7C2140%2C2000%7C41l4vVJMxEL.png%7C0%2C0%2C2140%2C2000%2B0.0%2C0.0%2C2140.0%2C2000.0_AC_SX342_SY445_.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Here I utilised html parser to parse\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "title_element = soup.find(id=\"productTitle\")\n",
        "title = title_element.get_text()\n",
        "title = title.strip()\n",
        "\n",
        "rating_element = soup.find(id=\"acrPopover\")\n",
        "rating = rating_element.get(\"title\")\n",
        "rating = rating.replace('out of 5 stars', '')\n",
        "\n",
        "price_element = soup.find('span', class_='a-price')\n",
        "price_element = price_element.find('span', class_='a-offscreen')\n",
        "price = price_element.get_text()\n",
        "price = price.strip()\n",
        "\n",
        "print(title)\n",
        "print(rating)\n",
        "print(price)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHpZqyzG1RNa",
        "outputId": "b08f95c5-bb06-478a-e792-d602aadc8d24"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got Data Funny Business Data Analyst T-Shirt\n",
            "4.4 \n",
            "$19.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_listing(listing_url):\n",
        "    response = requests.get(listing_url, headers=headers)\n",
        "    soup_search= BeautifulSoup(response.text, \"lxml\")\n",
        "    link_elements = soup_search.select(\"[data-asin] h2 a\")\n",
        "    page_data = []\n",
        "    for link in link_elements:\n",
        "        full_url = urljoin(listing_url, link.attrs.get(\"href\"))\n",
        "        product_info = get_product_info(full_url)\n",
        "        page_data.append(product_info)\n",
        "\n",
        "    next_page_el = soup_search.select_one('a:contains(\"Next\")')\n",
        "    if next_page_el:\n",
        "        next_page_url = urljoin(listing_url, next_page_el.attrs.get(\"href\"))\n",
        "        page_data += parse_listing(next_page_url)\n",
        "\n",
        "    return page_data\n",
        "\n",
        "    df = pd.DataFrame(page_data)\n",
        "    df.head()\n",
        "\n",
        "    print(df)"
      ],
      "metadata": {
        "id": "h4I2cER07x1J"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# ... (your existing code) ...\n",
        "\n",
        "# Create a list of dictionaries to store the data\n",
        "data = [{'Title': title, 'Rating': rating, 'Price': price, 'Image URL': image_url}]\n",
        "\n",
        "# Specify the CSV file name\n",
        "csv_file = 'amazon_product_data.csv'\n",
        "\n",
        "# Write the data to the CSV file\n",
        "with open(csv_file, 'w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=data[0].keys())\n",
        "    writer.writeheader()  # Write the header row\n",
        "    writer.writerows(data)  # Write the data rows\n",
        "\n",
        "print(f\"Data exported to {csv_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OanivxhAoTd",
        "outputId": "f77020ba-1fd6-4f0e-fc6a-2c8f2c165764"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data exported to amazon_product_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#As an excel file\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Specify the Excel file name\n",
        "excel_file = 'amazon_product_data.xlsx'\n",
        "\n",
        "# Export the DataFrame to Excel\n",
        "df.to_excel(excel_file, index=False)  # Set index=False to avoid writing row numbers\n",
        "\n",
        "print(f\"Data exported to {excel_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLlaf7opBbAR",
        "outputId": "50a8dc68-e916-48eb-c3e9-413ba50b7f79"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data exported to amazon_product_data.xlsx\n"
          ]
        }
      ]
    }
  ]
}